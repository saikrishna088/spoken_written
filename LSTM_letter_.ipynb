{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "LSTM_letter_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "767H_LKpHzkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FiicXmSGdgN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IZhhi0CIHF",
        "colab_type": "code",
        "outputId": "19808204-0fe0-41d1-87cc-1b1bcc05f785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsOdxfKqRpe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dr=\"/content/drive/My Drive/Classroom/Datasets/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ysezk7LTBUI",
        "colab_type": "code",
        "outputId": "ee2ff309-fed9-4e66-ea67-baa8828e3397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "import os\n",
        "os.listdir(dr)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B',\n",
              " 'donar_preprocess.csv',\n",
              " 'donar_tfselected_words.csv',\n",
              " 'chunk3_train_sparse_matrix.npz',\n",
              " 'chunk2_train_sparse_matrix.npz',\n",
              " 'chunk1_train_sparse_matrix.npz',\n",
              " 'sample_test_sparse_matrix.npz',\n",
              " 'Donesaving_reg1.csv',\n",
              " 'reg_test.csv',\n",
              " 'reg_train1.csv',\n",
              " 'Donesaving_reg2.csv',\n",
              " 'reg_train2.csv',\n",
              " 'reg_train3.csv',\n",
              " 'random_file_size.csv',\n",
              " 'srandom_parse_matrix.npz',\n",
              " 'top_feat_names.npy',\n",
              " 'top_feat_indexs.npy',\n",
              " 'file_name_list.npy',\n",
              " 'file_size.csv',\n",
              " 'samplebyte_images.rar',\n",
              " 'samplebyte_images',\n",
              " 'trainLabels.csv',\n",
              " 'result.csv',\n",
              " 'asmoutputfile.csv',\n",
              " 'asm_result_with_size.csv',\n",
              " 'one_data.csv',\n",
              " 'final_byte.csv',\n",
              " 'cnn_feat.csv',\n",
              " 'IMDB_files_csv',\n",
              " 'en_train.csv',\n",
              " 'model_INT',\n",
              " 'label_model.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm5wp9esRppm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is just to know how much time will it take to run this entire ipython notebook \n",
        "from datetime import datetime\n",
        "# globalstart = datetime.now()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import os\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8jodw89z0Yd",
        "colab_type": "code",
        "outputId": "10cbd7ed-d1ff-404a-9445-61bdd911e685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector, Activation, TimeDistributed, Dense, RepeatVector, Embedding, Bidirectional,Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcAKiqkz0Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J2Mmb7HWfdui",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(dr+\"en_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnPUySn5kHBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=df[df['sentence_id']<=150000]#taking 1.5 million sentence data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRO7YMm-tdMb",
        "colab_type": "code",
        "outputId": "9c72043d-dccc-4412-8a69-b133f8794d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "data['class'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PLAIN         1418821\n",
              "PUNCT          367436\n",
              "DATE            54281\n",
              "LETTERS         28991\n",
              "CARDINAL        25820\n",
              "VERBATIM        15076\n",
              "MEASURE          3092\n",
              "ORDINAL          2385\n",
              "DECIMAL          2022\n",
              "MONEY            1224\n",
              "DIGIT            1011\n",
              "ELECTRONIC        957\n",
              "TELEPHONE         738\n",
              "TIME              245\n",
              "FRACTION          228\n",
              "ADDRESS            96\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37InPqPI0jYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"new_class\"]=data['class'].apply(lambda c: \"NUMERIC\" if str(c)=='DATE' or  str(c)=='CARDINAL' or  str(c)=='MEASURE' or  str(c)=='ORDINAL' or  str(c)=='DECIMAL' or  str(c)=='MONEY' or  str(c)=='DIGIT' or  str(c)=='TELEPHONE' or str(c)=='TIME' or str(c)=='FRACTION' or  str(c)=='ADDRESS' else( \"PLAIN_PUNC\" if str(c)=='PLAIN' or str(c)=='PUNCT' else( \"LETTERS_VERB\" if str(c)=='LETTERS' or str(c)=='VERBATIM' else c ) ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRmVYPrHshLx",
        "colab_type": "code",
        "outputId": "7f25be2d-7de6-4604-e542-28db6ce7866d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "data[\"new_class\"].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PLAIN_PUNC      1786257\n",
              "NUMERIC           91142\n",
              "LETTERS_VERB      44067\n",
              "ELECTRONIC          957\n",
              "Name: new_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hD1ulNxThl8",
        "colab_type": "code",
        "outputId": "9c6f9b0e-1fec-4ac9-c8f4-1af30fbb7673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1922423, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rd0OD-akYyO",
        "colab_type": "code",
        "outputId": "058d185a-20fc-449c-95c9-5450fb9161a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "data.head(11)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>token_id</th>\n",
              "      <th>class</th>\n",
              "      <th>before</th>\n",
              "      <th>after</th>\n",
              "      <th>new_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>Brillantaisia</td>\n",
              "      <td>Brillantaisia</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>is</td>\n",
              "      <td>is</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>genus</td>\n",
              "      <td>genus</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>plant</td>\n",
              "      <td>plant</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>family</td>\n",
              "      <td>family</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>PLAIN</td>\n",
              "      <td>Acanthaceae</td>\n",
              "      <td>Acanthaceae</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PLAIN_PUNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>DATE</td>\n",
              "      <td>2006</td>\n",
              "      <td>two thousand six</td>\n",
              "      <td>NUMERIC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_id  token_id  class         before             after   new_class\n",
              "0             0         0  PLAIN  Brillantaisia     Brillantaisia  PLAIN_PUNC\n",
              "1             0         1  PLAIN             is                is  PLAIN_PUNC\n",
              "2             0         2  PLAIN              a                 a  PLAIN_PUNC\n",
              "3             0         3  PLAIN          genus             genus  PLAIN_PUNC\n",
              "4             0         4  PLAIN             of                of  PLAIN_PUNC\n",
              "5             0         5  PLAIN          plant             plant  PLAIN_PUNC\n",
              "6             0         6  PLAIN             in                in  PLAIN_PUNC\n",
              "7             0         7  PLAIN         family            family  PLAIN_PUNC\n",
              "8             0         8  PLAIN    Acanthaceae       Acanthaceae  PLAIN_PUNC\n",
              "9             0         9  PUNCT              .                 .  PLAIN_PUNC\n",
              "10            1         0   DATE           2006  two thousand six     NUMERIC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3vCzlw4d2us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=data[data['new_class']=='LETTERS_VERB']\n",
        "num_df=data[data['new_class']=='NUMERIC']\n",
        "df.columns=['sentence_id',\t'token_id',\t'class',\t'written',\t'spoken',\t'new_class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BETplmHLW2WX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "752015d4-eb4f-418e-fa93-d1ac453a5c88"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>token_id</th>\n",
              "      <th>class</th>\n",
              "      <th>written</th>\n",
              "      <th>spoken</th>\n",
              "      <th>new_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>IUCN</td>\n",
              "      <td>i u c n</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>BC</td>\n",
              "      <td>b c</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>ALCS</td>\n",
              "      <td>a l c s</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>VERBATIM</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>C.</td>\n",
              "      <td>c</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_id  token_id     class written   spoken     new_class\n",
              "11             1         1   LETTERS    IUCN  i u c n  LETTERS_VERB\n",
              "115            9         2   LETTERS      BC      b c  LETTERS_VERB\n",
              "159           14         2   LETTERS    ALCS  a l c s  LETTERS_VERB\n",
              "162           14         5  VERBATIM       -        -  LETTERS_VERB\n",
              "201           18         2   LETTERS      C.        c  LETTERS_VERB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3ndAleWz0Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "#tokenizer.texts_to_sequences('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_yksm1_iy5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['spoken','written']]=df[['spoken','written']].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut9KJxuYz0Y6",
        "colab_type": "code",
        "outputId": "7cd3abe3-a605-4ee7-8a05-2e7ed727d0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare  spoken tokenizer\n",
        "\n",
        "#spoken_tokenizer =Tokenizer()\n",
        "spoken_tokenizer=tokenization(df[\"spoken\"])\n",
        "spoken_vocab_size = len(spoken_tokenizer.word_index) + 1\n",
        "\n",
        "spoken_length = 20\n",
        "print('Size of English spoken Vocabulary : %d' % spoken_vocab_size)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of English spoken Vocabulary : 1376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzSrzW2vz0Y9",
        "colab_type": "code",
        "outputId": "026756e6-bf18-43b7-d601-53c389b9f528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare written tokenizer\n",
        "#written_tokenizer =Tokenizer()\n",
        "written_tokenizer=tokenization(df[\"written\"])\n",
        "written_vocab_size = len(written_tokenizer.word_index) + 1\n",
        "\n",
        "written_length = 20\n",
        "print('Size of English written Vocabulary : %d' % written_vocab_size)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of English written Vocabulary : 7723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WY0oNJ-z0Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVKpdzhVz0ZC",
        "colab_type": "text"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOWhohbfgInh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b4fba8fb-8e0f-4ac4-ebe9-98ea2f2e159e"
      },
      "source": [
        "df['spoken'].apply(lambda l: len(l))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11         7\n",
              "115        3\n",
              "159        7\n",
              "162        1\n",
              "201        1\n",
              "          ..\n",
              "1921948    3\n",
              "1921983    3\n",
              "1922171    3\n",
              "1922247    1\n",
              "1922320    3\n",
              "Name: spoken, Length: 44067, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iimr_sWfz0ZF",
        "colab_type": "code",
        "outputId": "71d2876b-436f-4c53-c805-afc8a21cada2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "df.head(15)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>token_id</th>\n",
              "      <th>class</th>\n",
              "      <th>written</th>\n",
              "      <th>spoken</th>\n",
              "      <th>new_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>IUCN</td>\n",
              "      <td>i u c n</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>BC</td>\n",
              "      <td>b c</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>ALCS</td>\n",
              "      <td>a l c s</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>VERBATIM</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>C.</td>\n",
              "      <td>c</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>J.</td>\n",
              "      <td>j</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>G.</td>\n",
              "      <td>g</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>u s</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>VERBATIM</td>\n",
              "      <td>#</td>\n",
              "      <td>number</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>LP</td>\n",
              "      <td>l p</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>Aceh</td>\n",
              "      <td>a c e h</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>Aceh</td>\n",
              "      <td>a c e h</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>NJ</td>\n",
              "      <td>n j</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>54</td>\n",
              "      <td>11</td>\n",
              "      <td>VERBATIM</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>and</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>56</td>\n",
              "      <td>8</td>\n",
              "      <td>LETTERS</td>\n",
              "      <td>Lviv</td>\n",
              "      <td>l v i v</td>\n",
              "      <td>LETTERS_VERB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_id  token_id     class written   spoken     new_class\n",
              "11             1         1   LETTERS    IUCN  i u c n  LETTERS_VERB\n",
              "115            9         2   LETTERS      BC      b c  LETTERS_VERB\n",
              "159           14         2   LETTERS    ALCS  a l c s  LETTERS_VERB\n",
              "162           14         5  VERBATIM       -        -  LETTERS_VERB\n",
              "201           18         2   LETTERS      C.        c  LETTERS_VERB\n",
              "205           18         6   LETTERS      J.        j  LETTERS_VERB\n",
              "209           18        10   LETTERS      G.        g  LETTERS_VERB\n",
              "224           19         1   LETTERS    U.S.      u s  LETTERS_VERB\n",
              "279           24         3  VERBATIM       #   number  LETTERS_VERB\n",
              "317           26         8   LETTERS      LP      l p  LETTERS_VERB\n",
              "397           31         5   LETTERS    Aceh  a c e h  LETTERS_VERB\n",
              "399           31         7   LETTERS    Aceh  a c e h  LETTERS_VERB\n",
              "503           40         2   LETTERS      NJ      n j  LETTERS_VERB\n",
              "724           54        11  VERBATIM       &      and  LETTERS_VERB\n",
              "744           56         8   LETTERS    Lviv  l v i v  LETTERS_VERB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvM9Am_lz0ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPLITTING DATA\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df[['spoken','written']], test_size=0.28, random_state = 42)\n",
        "# prepare training data\n",
        "trainX = encode_sequences(spoken_tokenizer, spoken_length, train.iloc[:,0])\n",
        "trainY = encode_sequences(written_tokenizer, written_length, train.iloc[:,1])\n",
        "# prepare validation data\n",
        "testX = encode_sequences(spoken_tokenizer, spoken_length, test.iloc[:,0])\n",
        "testY = encode_sequences(written_tokenizer, written_length, test.iloc[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXDEfA6BtPal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5140d0fb-82ea-4f5f-d325-13f86de4506e"
      },
      "source": [
        "trainX.shape,trainY.shape,spoken_length,written_length,spoken_vocab_size,written_vocab_size"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31728, 20), (31728, 20), 20, 20, 1376, 7723)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0sdIZLIz0ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(spoken_vocab_size, 512, input_length=spoken_length, mask_zero=True))\n",
        "\n",
        "model.add(LSTM(512))\n",
        "model.add(RepeatVector(written_length))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dense(written_vocab_size, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsZr-DeXz0ZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/\n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rSMLCD5z0ZQ",
        "colab_type": "code",
        "outputId": "0c0dfa25-2ba2-4487-9fae-19a6649e097b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "source": [
        "filename =dr+\"letter_model.h5\"\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1 ),  \n",
        "          epochs=8, batch_size=32, \n",
        "          validation_split = 0.25,\n",
        "          callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 23796 samples, validate on 7932 samples\n",
            "Epoch 1/8\n",
            "23796/23796 [==============================] - 626s 26ms/step - loss: 0.1544 - acc: 0.9781 - val_loss: 0.1624 - val_acc: 0.9773\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.16238, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n",
            "Epoch 2/8\n",
            "23796/23796 [==============================] - 623s 26ms/step - loss: 0.1423 - acc: 0.9793 - val_loss: 0.1566 - val_acc: 0.9788\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.16238 to 0.15656, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n",
            "Epoch 3/8\n",
            "23796/23796 [==============================] - 630s 26ms/step - loss: 0.1329 - acc: 0.9799 - val_loss: 0.1510 - val_acc: 0.9796\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.15656 to 0.15096, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n",
            "Epoch 4/8\n",
            "23796/23796 [==============================] - 620s 26ms/step - loss: 0.1267 - acc: 0.9808 - val_loss: 0.1504 - val_acc: 0.9791\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.15096 to 0.15038, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n",
            "Epoch 5/8\n",
            "23796/23796 [==============================] - 619s 26ms/step - loss: 0.1220 - acc: 0.9811 - val_loss: 0.1480 - val_acc: 0.9796\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.15038 to 0.14796, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n",
            "Epoch 6/8\n",
            "23796/23796 [==============================] - 628s 26ms/step - loss: 0.1193 - acc: 0.9816 - val_loss: 0.1487 - val_acc: 0.9804\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.14796\n",
            "Epoch 7/8\n",
            "23796/23796 [==============================] - 621s 26ms/step - loss: 0.1163 - acc: 0.9819 - val_loss: 0.1489 - val_acc: 0.9799\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.14796\n",
            "Epoch 8/8\n",
            "23796/23796 [==============================] - 621s 26ms/step - loss: 0.1129 - acc: 0.9823 - val_loss: 0.1470 - val_acc: 0.9804\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.14796 to 0.14703, saving model to /content/drive/My Drive/Classroom/Datasets/label_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGlKUExUoRQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving spoken token\n",
        "with open(dr+'letter_spoken_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(spoken_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1CSGRvvpwmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving written token\n",
        "with open(dr+'letter_written_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(written_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXZtEqj_oRWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading\n",
        "with open(dr+'letter_spoken_tokenizer.pickle', 'rb') as handle:\n",
        "    sp_t = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}